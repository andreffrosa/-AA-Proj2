Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. In case of doubt, you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.
- You can include references to images or html files such as the reports generated with clusters. To do this, simply include this document in the folder with the reports or images and refer them in the text by the file name in an isolated line. For example, the line

test.png

refers to a test.png image file in the same folder as this document.

QUESTIONS:

Q1: Explain how you selected the best attributes for the clustering phase. In particular, indicate the visualization methods used to explore the extracted attributes and any statistical tests used.
R1: First, after extracting the features, I clustered them, wich resultuded in a new set of features with half the dimension.
    After that, I used the A-NOVA F-test to select the best features and iterated the number of best features to extract from 1 to number_of_features.
    For each number of features to extract, I exploited a range of parameters (n_clustes, eps, ...) for each Clustering algorithm.


Q2: After selecting the attributes, did you standardize or normalize the values? Justify your decision.
R2: I standardized the values of the features because after extracting them, bacause TNSE and ISOMAP distort the values, the variables end up with different scales and thus need to be standardized in order to be on the same scale. 


Q3: Explain how you found the neighborhood radius value (epsilon) for the DBSCAN algorithm by following the procedure described in the article "A density-based algorithm for discovering clusters in large spatial databases with noise".
R3: First I computed the distances to the 5th neighbor of all points. Then, sorted the distances in descending order. Finnally, I draw the plot and visually selected the first valley as the value for epsilon.


Q4: Examining the clusters generated by the DBSCAN algorithm with the value optimized by the method described in the article, do you think the result is adequate to cluster these images? Justify your answer.
R4: No, DBSCAN usually produced only 1 cluster, which is almost the same as not clustering. 
    This is due to all the points being "condensed" in a single density "zone", and thus DBSCAn only returns 1 cluster (and noise) with the proposed method.


Q5: Describe your analysis of the k (for K-Means) and epsilon (for DBSCAN) parameters using the internal and external indicators referred in the assignment page. Include the two plots of the indicator values ​​(indicating the image name of each plot in one line in your answer) as a function of the k and epsilon parameters and explain how you chose the ranges for examining these parameters. Indicate, with justification, what conclusions you can draw from this analysis.
R5: For K-Means, I enforced a precision above (or equal than) 0.75 and a cohesion less (or equal) than 0.35 and for the points that respected that condition, I maximized the f1 score. 
    maximizing the precision results in more similar clusters, however, increasing the precision too much leads to many clusters. 
    Therefore, I set a lower bound of 0.75instead of maximizing precision.
    For the points that respect the previous condiditon, there needs to be a tiebreaker. I choosed cohesion, prefering more "tight" clusters since it gives more closer images. 
    However, maximizing cohesion leads to the same problem of the precision, too many clusters. 
    Therefore, I set an upper bound of 0.35 for cohesion.
    Finnaly, to tiebreak the points, I maximized the f1 score, prefering more balanced clusters.
    The range of values were for the number of clusters was an interval of 15 values from (563/70) to (563/20), i.e., assuming that the clusters were all of similar size, the cluster's size was between 70 and 20 points.
    From this analysis I conclude that considering only a precision metric, in this case, is a bad idea since it gives too "mixed up" clusters or too many clusters and thus more metrics should be considered to obtain a satisfaible result.
    in the case of DBSCAN, I tried to maximize the precision, since this algorithm since the previous method wasn't adequate for DBSCAN with these images. Even then, DBSCAN had few clusters with a "big" cluster, i.e., it was too bad.
    The range for DBSCAN was obtain by: linspace(0.1*563, 0.4*563, num=30). The 0.1 and 0.4 were choosed because the first valley (method of obtaining epsilon in the paper) is usually situated between 10% and 40% of the range of distances and I wanted try to verify if decreasing the eps would bring better results (therefore being 40% instead of only 15% or 20%).
    I conclude that DBSCAN is not a good algorithm to employ in this scenario (There are only a condesend region).

    AGG-5F.png
    
    B-KMEANS-4F.png
    
    DBSCAN-7F.png
    
    KMEANS-5F.png
    
    AGG.html
    
    B-KMEANS.html
    
    DBSCAN.html
    
    KMEANS.html

    
Q6: Select some of the parameter values ​​tested in question five and examine the corresponding clusters more closely, generating the HTML file with the images. Explain how you selected these parameter values, discuss the different options and propose a recommendation that could help the biologists' task of classifying cells and rejecting segmentation errors.
R6: I explained how I obtained the parameter values in the previous question. Summary: I iterated through 1 to number of features (being k the iterated number), selecting the best K features and for each iterated trhroug a range of values for the parameter and selected the one that maximez a score function defined by me.
    Too help biologists, first they would need to manually label a small random sample of the images (like they gave us in this project). Then, extract the 18 features, cluster them and select the best 5. After that, with that labels, run the optimization algorithm described in the previous 2 questions to find the n_clusters value that maximizes the score.
    Finnaly, present to the biologists the clusters generated.

Q7: Discuss advantages or problems with these two algorithms (K-Means and DBSCAN) for the purpose of helping biologists to organize these images, considering your theoretical knowledge of these algorithms as well as the results you obtained in your work.
R7: KMEANS agregates the values that are closer to the mean of the cluster (centroids). In this case, since all the images are in a big density zone, resorting to this method seems bring good results. However, this algorithm has a random part, being non-deterministic, and thus resulting in diferente cluster every time it is applied to the same data, being that a disanvantage.
    In the case o DBSCAN, since all the images are in a big density zone, this algorithm is not adequate to be applied. However, if the images were scattered throug multiple density zones, separated by sparce zones, then it would be an algorithm worth considering.

Q8: Consider other clustering algorithms embedded in the Scikit-Learn library. Choose one and apply it to this problem, optimizing the parameters you deem appropriate in the way that you find adequate. Justify your choices and discuss whether this option would yield more useful results for biologists.
R8: I choosed Agglomerative Clustering with Neighborhoods. I choosed this algorithm since we want to group images based on their similarity. I found the adeuqate parameter in the same way as KMEANS. This algorithm was the best of all the tested algorithms because it gave larger clusters with "almost-identical" images, on average.
    Therefore, this optiion would help more the biologists more than KMEANS.

Q9: (Optional) Implement the Bissecting K-Means hierarchical clustering algorithm as described in the assignment page and Lecture 19. Examine and discuss the results and their application to the problem of helping the biologists select and classify cell images.
R9: I used as score to chose the cluster to divied , the size, having tried also the cohesion. Bissecting KMEANS performed well, having similar results to K-Means, but slightly better (clusters more similar and erros were more "isolated" in a cluster). However, it is much slower.
